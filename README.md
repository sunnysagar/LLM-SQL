# LLM-SQL APP

This project demonstrates two key tasks:

1. **LLM-powered chat API** using FastAPI + FAISS + multiple providers (OpenAI, Claude, Grok)
2. **Async SQLAlchemy ORM** for managing Users and Messages with full CRUD functionality

---

## üöÄ Tech Stack

- **Backend**: Python, FastAPI
- **Database**: SQLite (with Async SQLAlchemy ORM)
- **Vector Search**: FAISS
- **LLMs Supported**:
    - OpenAI (GPT-4, GPT-3.5)
    - Anthropic Claude (Claude 3 Opus)
    - Grok (simulated/mock structure using `httpx`)

---

## üì¶ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/sunnysagar/llm-sql.git
cd llm-sql
```

### 2. Create virtual environment & activate

```bash
python -m venv venv
# On Windows:
venv\Scripts\activate
# On Linux or Mac:
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure environment variables

Create a `.env` file in the project root and add:

```
OPENAI_API_KEY=your-openai-key
CLAUDE_API_KEY=your-claude-key
GROK_API_KEY=your-grok-api-key
LLM_PROVIDER=openai
```

---

## üîß Run Instructions

1. **Install dependencies:**  (If not done yet)

        ```bash
        pip install -r requirements.txt
        ```

2. **Run the app:**

        ```bash
        uvicorn app.main:app --reload
        ```

3. **Access the interactive API docs:**  
     [http://localhost:8000/docs](http://localhost:8000/docs)

---

## üîπ Task 1: `/chat` Endpoint with LLM Integration

- Accepts a user query via a REST API endpoint.
- Performs semantic search using FAISS to retrieve relevant context from a knowledge base.
- Supports integration with multiple LLM providers: **OpenAI**, **Claude**, and **Grok**.
- LLM provider can be selected and configured via environment variables or settings.
- Returns a context-aware response generated by the selected LLM.

**Architecture:**

```
User Query ‚Üí FAISS Search ‚Üí Combine Context + Prompt ‚Üí Call LLM (OpenAI/Claude/Grok) ‚Üí Return Response
```

---

## üîπ Task 2: Full CRUD with Async SQLAlchemy

**Features**
- Defines two main models: **User** and **Message**.
- Implements asynchronous database operations using SQLAlchemy with an SQLite backend.
- Provides FastAPI endpoints for full Create, Read, Update, and Delete (CRUD) operations on both models.
- Includes endpoints to list all messages for a specific user.
- Ensures non-blocking I/O for improved performance and scalability.

**Models:**

- **User**: name, email
- **Message**: content, linked to user via foreign key

**Endpoints:**

- `POST /users`, `GET /users`, `PUT /users/{id}`, `DELETE /users/{id}`
- `POST /messages`, `GET /messages`, etc.
- `GET /users/{user_id}/messages`: fetch all messages for a user

**Tech:**

- `sqlalchemy.ext.asyncio`
- `async_sessionmaker`
- Clean separation into schemas, crud, routes, and models

---

## ‚ö†Ô∏è Disclaimer

This project is for educational and demonstration purposes only. Use at your own risk. API keys and credentials should never be committed to source control. The authors are not responsible for any misuse or data loss.
