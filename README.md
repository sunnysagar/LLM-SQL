# LLM-SQL APP

## ðŸ”¹ Task 1: `/chat` Endpoint with LLM Integration

- Accepts a user query via a REST API endpoint.
- Performs semantic search using FAISS to retrieve relevant context from a knowledge base.
- Supports integration with multiple LLM providers: **OpenAI**, **Claude**, and **Grok**.
- LLM provider can be selected and configured via environment variables or settings.
- Returns a context-aware response generated by the selected LLM.

## ðŸ”¹ Task 2: Full CRUD with Async SQLAlchemy

- Defines two main models: **User** and **Message**.
- Implements asynchronous database operations using SQLAlchemy with an SQLite backend.
- Provides FastAPI endpoints for full Create, Read, Update, and Delete (CRUD) operations on both models.
- Includes endpoints to list all messages for a specific user.
- Ensures non-blocking I/O for improved performance and scalability.

## ðŸ”§ Run Instructions

1. **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

2. **Run the app:**
    ```bash
    uvicorn app.main:app --reload
    ```

3. **Access the interactive API docs:**  
   [http://localhost:8000/docs](http://localhost:8000/docs)